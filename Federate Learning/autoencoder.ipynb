{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dfTrain=pd.read_csv(\"Train.csv\")\n",
    "df_train_id002=pd.read_csv(\"train_id0002.csv\")\n",
    "df_train_id003=pd.read_csv(\"train_id0003.csv\")\n",
    "df_train_id006=pd.read_csv(\"train_id0006.csv\")\n",
    "dfTest=pd.read_csv(\"Test.csv\")\n",
    "dfValidation=pd.read_csv(\"Validation.csv\")\n",
    "\n",
    "\n",
    "epochs=5\n",
    "iterations=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['EngSpeed', 'EngOilPress', 'EngCoolantTemp', 'EngFuelRate', 'BatteryPotential_PowerInput1', 'ActualEngPercentTorque', 'BarometricPress', 'EngPercentLoadAtCurrentSpeed', 'NominalFrictionPercentTorque', 'EngsDesiredOperatingSpeed', 'EngIntakeManifold1Temp', 'EngIntakeManifold1Press']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def create_autoencoder(input_dim, encoding_dim=128):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(encoding_dim, activation='tanh'),\n",
    "        layers.Dense(2, activation='tanh'),\n",
    "        layers.Dense(encoding_dim, activation='tanh'),\n",
    "        layers.Dense(input_dim, activation='tanh')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(columns)\n",
    "\n",
    "def federated_average(models):\n",
    "    # Inicializa el modelo global\n",
    "    global_model = create_autoencoder(input_dim)\n",
    "\n",
    "    # Extrae pesos de cada modelo local\n",
    "    local_weights = [model.get_weights() for model in models]\n",
    "\n",
    "    # Promedia los pesos\n",
    "    avg_weights = []\n",
    "    for weights in zip(*local_weights):\n",
    "        avg_weights.append(np.mean(weights, axis=0))\n",
    "\n",
    "    # Asigna los pesos promedio al modelo global\n",
    "    global_model.set_weights(avg_weights)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "游대 Federated Iteration 1\n",
      "  Entrenando cliente 1\n",
      "  Entrenando cliente 2\n",
      "  Entrenando cliente 3\n",
      "  游댌 Validation Loss after Round 1: 1.543114\n",
      "\n",
      "游대 Federated Iteration 2\n",
      "  Entrenando cliente 1\n",
      "  Entrenando cliente 2\n",
      "  Entrenando cliente 3\n",
      "  游댌 Validation Loss after Round 2: 1.544053\n",
      "\n",
      "游대 Federated Iteration 3\n",
      "  Entrenando cliente 1\n",
      "  Entrenando cliente 2\n",
      "  Entrenando cliente 3\n",
      "  游댌 Validation Loss after Round 3: 1.546190\n",
      "\n",
      "游대 Federated Iteration 4\n",
      "  Entrenando cliente 1\n",
      "  Entrenando cliente 2\n",
      "  Entrenando cliente 3\n",
      "  游댌 Validation Loss after Round 4: 1.554206\n",
      "\n",
      "游대 Federated Iteration 5\n",
      "  Entrenando cliente 1\n",
      "  Entrenando cliente 2\n",
      "  Entrenando cliente 3\n",
      "  游댌 Validation Loss after Round 5: 1.559056\n"
     ]
    }
   ],
   "source": [
    "# Dimensiones\n",
    "input_dim = len(columns)\n",
    "\n",
    "global_model = create_autoencoder(input_dim)\n",
    "\n",
    "for round_num in range(iterations):\n",
    "    print(f\"\\n游대 Federated Iteration {round_num + 1}\")\n",
    "    \n",
    "    local_models = []\n",
    "\n",
    "    # Entrenamiento local en cada cliente\n",
    "    for i, df in enumerate([df_train_id002, df_train_id003, df_train_id006]):\n",
    "        print(f\"  Entrenando cliente {i+1}\")\n",
    "        \n",
    "        # Clonar el modelo global (estructura) y copiar pesos\n",
    "        local_model = create_autoencoder(input_dim)\n",
    "        local_model.set_weights(global_model.get_weights())\n",
    "        \n",
    "        # Entrenamiento local\n",
    "        local_model.fit(df[columns], df[columns],\n",
    "                        epochs=epochs, batch_size=64, verbose=0)\n",
    "        \n",
    "        local_models.append(local_model)\n",
    "\n",
    "    # Promedio de pesos (FedAvg)\n",
    "    global_model = federated_average(local_models)\n",
    "\n",
    "    # Evaluaci칩n despu칠s de la ronda\n",
    "    val_loss = global_model.evaluate(dfValidation[columns], dfValidation[columns], verbose=0)\n",
    "    print(f\"  游댌 Validation Loss after Round {round_num + 1}: {val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model and determine threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the number of input features (columns in the dataset)\n",
    "input_dim = len(columns)  # Number of features\n",
    "encoding_dim = 128  # Number of neurons in the encoding layer\n",
    "\n",
    "# Columns that require modifications based on specific conditions\n",
    "columns_to_modify = [\"EngCoolantTemp\", \"EngIntakeManifold1Temp\"]\n",
    "\n",
    "# Define the Autoencoder model\n",
    "\n",
    "\n",
    "# Extract validation data for evaluation\n",
    "x_val = dfValidation[columns]\n",
    "\n",
    "# Generate predictions using the trained autoencoder\n",
    "predictions = global_model.predict(x_val)\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for each feature\n",
    "mse = pd.DataFrame(np.power(x_val - predictions, 2), columns=columns)\n",
    "\n",
    "# Dictionary to store the best threshold for each feature\n",
    "best_thresholds = {}\n",
    "\n",
    "# Iterate over each feature to find the best threshold using F1-score\n",
    "for column in columns:\n",
    "    mse_column = mse[column]  # Get MSE values for the column\n",
    "    best_f1 = 0  # Initialize best F1-score\n",
    "    best_threshold = 0  # Initialize best threshold value\n",
    "\n",
    "    # Try different percentile-based thresholds (from 50% to 100%)\n",
    "    for threshold_value in range(50, 101):\n",
    "        threshold = np.percentile(mse_column, threshold_value)  # Compute percentile threshold\n",
    "        anomaly_labels = (mse_column > threshold)  # Identify anomalies\n",
    "        y_pred_bool = ~anomaly_labels  # Convert to boolean normal/abnormal labels\n",
    "        \n",
    "        # Apply additional condition for specific columns\n",
    "        if column + \"_normal\" in columns_to_modify:\n",
    "            y_pred_bool = y_pred_bool | (dfValidation[\"within_5_minutes\"])\n",
    "        \n",
    "        y_test = dfValidation[column + \"_normal\"]  # Get actual labels\n",
    "        \n",
    "        # Compute F1-score\n",
    "        f1 = f1_score(y_test, y_pred_bool)\n",
    "        \n",
    "        # Update the best threshold if F1-score improves\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_threshold_value = threshold_value\n",
    "\n",
    "    # Store the best threshold for this feature\n",
    "    best_thresholds[column] = best_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 1s 2ms/step\n",
      "  Accuracy Precision  Recall F1 Score ROC AUC  PR AUC     TP   TN   FP   FN  \\\n",
      "0   94.12%    96.36%  97.18%   96.77%  80.72%  96.20%  10486  712  396  304   \n",
      "\n",
      "      TPR    FNR     TNR     FPR  \n",
      "0  97.18%  2.82%  64.26%  35.74%  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (f1_score, confusion_matrix, accuracy_score, \n",
    "                             precision_score, recall_score, roc_auc_score, average_precision_score)\n",
    "\n",
    "# List of columns that need modifications\n",
    "columns_to_modify = [\"EngCoolantTemp_normal\", \"EngIntakeManifold1Temp_normal\"]\n",
    "\n",
    "# Extract test data based on selected columns\n",
    "x_test = dfTest[columns]\n",
    "\n",
    "# Predict results using the autoencoder\n",
    "results = global_model.predict(x_test)\n",
    "\n",
    "# Compute Mean Squared Error (MSE) for each column\n",
    "mse = pd.DataFrame(np.power(x_test - results, 2), columns=columns)\n",
    "\n",
    "# Iterate over columns to determine anomalies\n",
    "for column in columns:\n",
    "    mse_column = mse[column]\n",
    "    best_threshold = best_thresholds[column]\n",
    "    anomaly_labels = (mse_column > best_threshold)\n",
    "    y_pred_bool = ~anomaly_labels\n",
    "    \n",
    "    # Modify prediction based on special condition\n",
    "    if column + \"_normal\" in columns_to_modify:\n",
    "        y_pred_bool = y_pred_bool | (dfTest[\"within_5_minutes\"])\n",
    "\n",
    "    dfTest[column + \"_normal_pred\"] = y_pred_bool\n",
    "\n",
    "# Determine final prediction by checking all normal predictions\n",
    "dfTest['normal_label_pred'] = dfTest[[col + \"_normal_pred\" for col in columns]].all(axis=1)\n",
    "\n",
    "# Extract actual and predicted labels for evaluation\n",
    "y_test_global = dfTest[\"normal_label\"]\n",
    "y_pred_global = dfTest['normal_label_pred']\n",
    "\n",
    "# Compute evaluation metrics\n",
    "confusion = confusion_matrix(y_test_global, y_pred_global)\n",
    "accuracy = accuracy_score(y_test_global, y_pred_global)\n",
    "precision = precision_score(y_test_global, y_pred_global)\n",
    "recall = recall_score(y_test_global, y_pred_global)\n",
    "f1 = f1_score(y_test_global, y_pred_global)\n",
    "roc_auc = roc_auc_score(y_test_global, y_pred_global)\n",
    "pr_auc = average_precision_score(y_test_global, y_pred_global)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "# Compute additional evaluation metrics\n",
    "TPR = TP / (TP + FN)  # Sensitivity\n",
    "FNR = FN / (FN + TP)  # False Negative Rate\n",
    "TNR = TN / (TN + FP)  # Specificity\n",
    "FPR = FP / (FP + TN)  # False Positive Rate\n",
    "\n",
    "# Create DataFrame to store results without additional statistics\n",
    "df_resultados_globales = pd.DataFrame([{\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1 Score\": f1,\n",
    "    \"ROC AUC\": roc_auc,\n",
    "    \"PR AUC\": pr_auc,\n",
    "    \"TP\": TP,\n",
    "    \"TN\": TN,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"TPR\": TPR,\n",
    "    \"FNR\": FNR,\n",
    "    \"TNR\": TNR,\n",
    "    \"FPR\": FPR\n",
    "}])\n",
    "\n",
    "# Format percentage-based metrics properly\n",
    "columns_to_exclude = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "for col in df_resultados_globales.columns:\n",
    "    if col not in columns_to_exclude:\n",
    "        df_resultados_globales[col] = df_resultados_globales[col].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "\n",
    "# Print and save the results\n",
    "print(df_resultados_globales)\n",
    "df_resultados_globales.to_csv(\"results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
